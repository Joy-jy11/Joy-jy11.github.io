---
layout: ../layouts/Layout.astro
title: "Art3D: Training-Free 3D Generation from Flat-Colored Illustration" 
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
favicon: favicon.svg
thumbnail: preview.png
---

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import MeshViewer from "../components/MeshViewer.astro";


import { ImageComparison } from "../components/ImageComparison.tsx";


import Splat from "../components/Splat.tsx"
import teaser from "../assets/teaser_v3.png"
import pipeline from "../assets/pipeline.png"
import p_trellis from "../assets/p_trellis.png"
import p_ours from "../assets/p_ours.png"
import p_gt from "../assets/p_gt.png"
import taco_ours from "../assets/taco_ours.png"
import taco_gt from "../assets/taco_gt.png"
import boy_ours from "../assets/boy_ours.png"
import boy_gt from "../assets/boy_gt.png"
import boy_ln3diff from "../assets/boy_ln3diff.png"
import r_ours from "../assets/r_ours.png"
import r_shape from "../assets/r_shape.png"
import dog_ours from "../assets/dog_ours.png"
import dog_lgm from "../assets/dog_lgm.png"
import fox_ours from "../assets/fox_ours.png"
import fox_instantmesh from "../assets/fox_instantmesh.png"
import man_ours from "../assets/man_ours.png"
import man_3dtopia from "../assets/man_3dtopia.png"
import results from "../assets/results.jpg"




import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Xiaoyan Cong",
      url: "https://oliver-cong02.github.io/",
      //institution: "Brown University",
      notes: ["*"],
    },
    {
      name: "Jiayi Shen",
      url:"https://www.linkedin.com/in/jiayi-shen-414ab11b7/",
      //institution: "Brown University",
      notes: ["*"],
    },
    {
      name: "Zekun Li",
      url: "https://kunkun0w0.github.io/",
      //institution: "Brown University",
    },
    {
      name: "Rao Fu",
      url: "https://freddierao.github.io/",
      //institution: "Brown University",
    },
    {
      name: "Tao Lu",
      url: "https://inspirelt.github.io/",
      //institution: "Brown University",
    },
    {
      name: "Srinath Sridhar",
      url: "https://cs.brown.edu/people/ssrinath/",
      //institution: "Brown University",
    },
  ]}
  conference="Brown University"
  notes={[
    {
      symbol: "*",
      text: "Equal Contribution",
    },
    {
      symbol: "â€ ",
      text: "author note two",
    },
  ]}
  links={[
    {
      name: "Paper",
      url: "",
      icon: "ri:file-pdf-2-line",
    },
    {
      name: "Code",
      url: "",
      icon: "ri:github-line",
    },
    {
      name: "arXiv",
      url: "",
      icon: "academicons:arxiv",
    },
    {
      name: "Data Gallery",
      url: "/gallery",
      icon: "ri:gallery-line",
    },
  ]}
  />


<Image source={teaser} altText="Diagram" />

<HighlightedSection>

## Abstract

Large-scale pre-trained image-to-3D generative models have exhibited remarkable capabilities in diverse shape generations.
However, most of them failed to synthesize plausible 3D assets when the reference image is flat-colored like hand drawings, 
which are often the most user-friendly input modalities in art content creation. To this end, we propose Art3D, a training-free 
method that can lift flat-colored 2D designs into 3D. By enhancing the three-dimensionality illusion of reference images based on 
the structure feature through pretrained 2D image generation models, Art3D is generalized to versatile painting styles. 
To benchmark the generalization performance of existing image-to-3D models on flat images without 3D feeling, we collect a new dataset, 
Flat-2D, with over 100 flat images. Experimental results demonstrate the performance and robustness of Art3D, exhibiting superior 
generalizable capacity and promising practical applicability. Our source code and dataset will be publicly available upon acceptance.




## Pipeline
<Figure>
  <Image slot="figure" source={pipeline} altText="Diagram of the transformer deep learning architecture." />
  <span slot="caption">Art3D adds 3D illusion to the flat-colored image through ControlNet based on the structure features, e.g., canny
edge or depth map. The mesh is then synthesized based on the proxy image and textured by baking information from the input.</span>
</Figure>



## Qualitative Results
<Figure>
  <Image slot="figure" source={results} altText="..." />
  <span slot="caption">We combine our augmentation module with InstantMesh [Xu 2024] and perform comparisons with state-of-the-art pre-trained image-to-3D methods Shap-E [Jun 2023], LN3Diff [Lan 2024], InstantMesh [Xu 2024], 3DTopia-XL [Chen 2024], LGM [Tang 2024] and Trellis [Xiang 2024] All the flat-shaped input images are from our curated dataset Flat-2D. Our augmentation module can significantly improve the geometry quality of generated 3D assets.</span>
</Figure>


## Visual Comparisons

<div style={{ 
  display: 'grid', 
  gridTemplateColumns: 'repeat(3, 1fr)', 
  gap: '1.5rem', 
  placeItems: 'center'
}}>

  <Figure>
    <ImageComparison slot="figure" client:load imageUrlOne={p_trellis.src} imageUrlTwo={p_ours.src} altTextOne="Trellis [Xiang 2024]" altTextTwo="Ours" />
  </Figure>

  <Figure>
    <ImageComparison slot="figure" client:load imageUrlOne={dog_lgm.src} imageUrlTwo={dog_ours.src} altTextOne="LGM [Tang 2024]" altTextTwo="Ours" />
  </Figure>

  <Figure>
    <ImageComparison slot="figure" client:load imageUrlOne={fox_instantmesh.src} imageUrlTwo={fox_ours.src} altTextOne="InstantMesh [Xu 2024]" altTextTwo="Ours" />
  </Figure>

  <Figure>
    <ImageComparison slot="figure" client:load imageUrlOne={man_3dtopia.src} imageUrlTwo={man_ours.src} altTextOne="3DTopia-XL [Chen 2024]" altTextTwo="Ours" />
  </Figure>

  <Figure>
    <ImageComparison slot="figure" client:load imageUrlOne={boy_ln3diff.src} imageUrlTwo={boy_ours.src} altTextOne="LN3Diff [Lan 2024]" altTextTwo="Ours" />
  </Figure>

   <Figure>
    <ImageComparison slot="figure" client:load imageUrlOne={r_shape.src} imageUrlTwo={r_ours.src} altTextOne="Shap-E [Jun 2023]" altTextTwo="Ours" />
  </Figure>

</div>

## Interactive 3D Mesh Gallery


<section class="grid grid-cols-7 grid-rows-4 gap-16 py-6">
  <MeshViewer src="/mesh/bird.glb" />
  <MeshViewer src="/mesh/bird2.glb" />
  <MeshViewer src="/mesh/sheep.glb" />
  <MeshViewer src="/mesh/raccoon.glb" />
  <MeshViewer src="/mesh/fly.glb" />
  <MeshViewer src="/mesh/reddit.glb" />
  <MeshViewer src="/mesh/elephant.glb" />
  
  <MeshViewer src="/mesh/taco.glb" />
  <MeshViewer src="/mesh/mad.glb" />
  <MeshViewer src="/mesh/person2.glb" />
  <MeshViewer src="/mesh/fox.glb" />
  <MeshViewer src="/mesh/pig.glb" />
  <MeshViewer src="/mesh/taco2.glb" />
  <MeshViewer src="/mesh/person3.glb" />
  
  <MeshViewer src="/mesh/cat.glb" />
  <MeshViewer src="/mesh/pinkbear.glb" />
  <MeshViewer src="/mesh/boy2.glb" />
  <MeshViewer src="/mesh/person4.glb" />
  <MeshViewer src="/mesh/person7.glb" />
  <MeshViewer src="/mesh/person6.glb" />
  <MeshViewer src="/mesh/axolotl.glb" />

  <MeshViewer src="/mesh/man.glb" />
  <MeshViewer src="/mesh/person9.glb" />
  <MeshViewer src="/mesh/person8.glb" />
  <MeshViewer src="/mesh/boysunglass.glb" />
  <MeshViewer src="/mesh/boy.glb" />
  <MeshViewer src="/mesh/person.glb" />
  <MeshViewer src="/mesh/cone.glb" />
  
</section>




</HighlightedSection>

## BibTeX citation

```bibtex
@misc{roman2024academic,
  author = "{Roman Hauksson}",
  title = "Academic Project Page Template",
  year = "2024",
  howpublished = "\url{https://research-template.roman.technology}",
}
```